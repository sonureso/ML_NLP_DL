{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing dataset of movie reviews using:\n",
    "    1. Using Vader - (Built into nltk at Georgia Tech)\n",
    "    2. Using Sentiwordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01- Using Vader Sentiment Analyser (Basics):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.608, 'neu': 0.392, 'pos': 0.0, 'compound': -0.4767}\n"
     ]
    }
   ],
   "source": [
    "#Normal Sentence:\n",
    "print(sia.polarity_scores(\"What a terrible restaurant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5106}\n",
      "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.34}\n",
      "{'neg': 0.5, 'neu': 0.5, 'pos': 0.0, 'compound': -0.6124}\n"
     ]
    }
   ],
   "source": [
    "#Emotions:\n",
    "print(sia.polarity_scores(\":D\"))\n",
    "print(sia.polarity_scores(\":/\"))\n",
    "#Idioms:\n",
    "print(sia.polarity_scores(\"the cumin was the kiss of death\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4926}\n",
      "{'neg': 0.0, 'neu': 0.463, 'pos': 0.537, 'compound': 0.5399}\n"
     ]
    }
   ],
   "source": [
    "#punctuation:\n",
    "print(sia.polarity_scores(\"the food was good\"))\n",
    "print(sia.polarity_scores(\"the food was good!\"))\n",
    "print(sia.polarity_scores(\"the food was good!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.428, 'neu': 0.572, 'pos': 0.0, 'compound': -0.457}\n",
      "{'neg': 0.0, 'neu': 0.563, 'pos': 0.437, 'compound': 0.5964}\n"
     ]
    }
   ],
   "source": [
    "#Negation:\n",
    "print(sia.polarity_scores(\"the food was not good!!\"))\n",
    "#Double Negation:\n",
    "print(sia.polarity_scores(\"the food was not the worst!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.452, 'pos': 0.548, 'compound': 0.5622}\n",
      "{'neg': 0.0, 'neu': 0.517, 'pos': 0.483, 'compound': 0.5777}\n"
     ]
    }
   ],
   "source": [
    "#Emphasis & Boosters(so,such,really):\n",
    "print(sia.polarity_scores(\"the food was good\"))\n",
    "print(sia.polarity_scores(\"the food was GOOD\"))\n",
    "print(sia.polarity_scores(\"the food was so good\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.213, 'neu': 0.452, 'pos': 0.335, 'compound': 0.3291}\n",
      "{'neg': 0.322, 'neu': 0.435, 'pos': 0.243, 'compound': -0.2263}\n"
     ]
    }
   ],
   "source": [
    "#Contrasting Conjunctions(but):\n",
    "print(sia.polarity_scores(\"I usually hate sea food but I liked this\"))\n",
    "\n",
    "#Incorrect prediction:\n",
    "print(sia.polarity_scores(\"I usually hate sea food and I liked this\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-Using Vader of data and check accuracy of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here i think the data we used, has not acuurate labels and so having low accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "def acc(a,b):\n",
    "    print('Accuracy(test Data): ',accuracy_score(a,b))\n",
    "    print('Confusion Matrix: \\n',pd.DataFrame(confusion_matrix(a,b)))\n",
    "    print('Classification Repost:\\n',classification_report(a,b,digits=3))\n",
    "    \n",
    "def add_sentiment(text):\n",
    "    r = sia.polarity_scores(text)['compound']\n",
    "    if(r>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data2.csv\",engine='python')\n",
    "tweets = list(df.tweet)\n",
    "_stopwords = set(stopwords.words('english') + list(punctuation) +\n",
    "                 [\"million\",\"billion\",\"year\",\"millions\",\"billions\",\n",
    "                  \"y/y\",\"'s'\",\"''\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for tweet in tweets:\n",
    "    words = word_tokenize(tweet.lower())\n",
    "    words=[word for word in words if word not in _stopwords]\n",
    "    words = ' '.join(words)\n",
    "    texts.append(words)\n",
    "df['new_twt'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(test Data):  0.37199542159481114\n",
      "Confusion Matrix: \n",
      "       0     1\n",
      "0  1308  1692\n",
      "1  1600   642\n",
      "Classification Repost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.450     0.436     0.443      3000\n",
      "           1      0.275     0.286     0.281      2242\n",
      "\n",
      "    accuracy                          0.372      5242\n",
      "   macro avg      0.362     0.361     0.362      5242\n",
      "weighted avg      0.375     0.372     0.373      5242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['pred1'] = df['tweet'].map(add_sentiment)\n",
    "df['pred2'] = df['new_twt'].map(add_sentiment)\n",
    "acc(df.label,df.pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-Using Sentiwordnet Basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\Starkx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('dog.n.01'),\n",
       " SentiSynset('frump.n.01'),\n",
       " SentiSynset('dog.n.03'),\n",
       " SentiSynset('cad.n.01'),\n",
       " SentiSynset('frank.n.02'),\n",
       " SentiSynset('pawl.n.01'),\n",
       " SentiSynset('andiron.n.01'),\n",
       " SentiSynset('chase.v.01')]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Similar words:\n",
    "list(swn.senti_synsets('Dog'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_senti(tweet):\n",
    "    weight = 0.0\n",
    "    words = word_tokenize(tweet.lower())\n",
    "    words=[word for word in words if word not in _stopwords]\n",
    "    for word in words:\n",
    "        try:\n",
    "            for meaning in list(swn.senti_synsets(word)):\n",
    "                if(meaning.pos_score() > meaning.neg_score()):\n",
    "                    weight = weight + (meaning.pos_score() - meaning.neg_score())\n",
    "                else:\n",
    "                    weight = weight - (meaning.neg_score() - meaning.pos_score())\n",
    "            #averaing of the above weight is required, use different variable.\n",
    "        except:\n",
    "            pass\n",
    "    if(weight > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred3'] = df['tweet'].map(get_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(test Data):  0.3992750858450973\n",
      "Confusion Matrix: \n",
      "      0     1\n",
      "0  846  2154\n",
      "1  995  1247\n",
      "Classification Repost:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.460     0.282     0.350      3000\n",
      "           1      0.367     0.556     0.442      2242\n",
      "\n",
      "    accuracy                          0.399      5242\n",
      "   macro avg      0.413     0.419     0.396      5242\n",
      "weighted avg      0.420     0.399     0.389      5242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc(df.label,df.pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [user, father, dysfunctional, selfish, drags, ...\n",
       "1       [user, user, thanks, lyft, credit, ca, n't, us...\n",
       "2                                       [bihday, majesty]\n",
       "3                  [model, love, u, take, u, time, ur, ñ]\n",
       "4                       [factsguide, society, motivation]\n",
       "                              ...                        \n",
       "5237    [lady, banned, kentucky, mall, user, jcpenny, ...\n",
       "5238    [user, omfg, 'm, offended, 'm, mailbox, 'm, pr...\n",
       "5239    [user, user, n't, balls, hashtag, say, weasel,...\n",
       "5240     [makes, ask, anybody, ..., .god, oh, thank, god]\n",
       "5241    [user, sikh, temple, vandalised, calgary, wso,...\n",
       "Name: new_twt, Length: 5242, dtype: object"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.new_twt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
