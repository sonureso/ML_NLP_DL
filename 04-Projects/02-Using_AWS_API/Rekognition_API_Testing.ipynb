{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting access key and id: \n",
    "key = pd.read_csv('credentials.csv')\n",
    "key_id = key['Access key ID'].values[0]\n",
    "access_key = key['Secret access key'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo = '01.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('rekognition',aws_access_key_id=key_id,aws_secret_access_key=access_key,region_name='us-east-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket List: ['sonuresob1']\n"
     ]
    }
   ],
   "source": [
    "# S3 bucket for uploading images into it.\n",
    "s3 = boto3.client('s3',aws_access_key_id=key_id,aws_secret_access_key=access_key)\n",
    "response = s3.list_buckets()\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "print(\"Bucket List: %s\" % buckets)\n",
    "\n",
    "\n",
    "\n",
    "#filename = '01.jpg'\n",
    "#bucket_name = 'sonuresob1'\n",
    "#newname = 'new.jpg'\n",
    "#s3.upload_file(filename, bucket_name, newname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3.create_bucket(Bucket='sonuresob2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   1. Label Detection:  Converting Images to its byte format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(photo,'rb') as source_image:\n",
    "    source_bytes = source_image.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Detecting Labels using bytes of images on local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.detect_labels(Image={'Bytes': source_bytes}, MaxLabels=10,MinConfidence=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'Name': 'Car',\n",
       "   'Confidence': 99.82917022705078,\n",
       "   'Instances': [{'BoundingBox': {'Width': 0.21661338210105896,\n",
       "      'Height': 0.2922539710998535,\n",
       "      'Left': 0.426487535238266,\n",
       "      'Top': 0.702470064163208},\n",
       "     'Confidence': 99.82917022705078},\n",
       "    {'BoundingBox': {'Width': 0.1579536497592926,\n",
       "      'Height': 0.1903790831565857,\n",
       "      'Left': 0.5933496356010437,\n",
       "      'Top': 0.5612152814865112},\n",
       "     'Confidence': 98.67333984375},\n",
       "    {'BoundingBox': {'Width': 0.05757751315832138,\n",
       "      'Height': 0.086023710668087,\n",
       "      'Left': 0.8268179893493652,\n",
       "      'Top': 0.5275430679321289},\n",
       "     'Confidence': 97.54666137695312},\n",
       "    {'BoundingBox': {'Width': 0.0489080436527729,\n",
       "      'Height': 0.08776109665632248,\n",
       "      'Left': 0.32941025495529175,\n",
       "      'Top': 0.442045122385025},\n",
       "     'Confidence': 97.23896789550781},\n",
       "    {'BoundingBox': {'Width': 0.0354219451546669,\n",
       "      'Height': 0.051243845373392105,\n",
       "      'Left': 0.47551241517066956,\n",
       "      'Top': 0.4181915819644928},\n",
       "     'Confidence': 96.51046752929688},\n",
       "    {'BoundingBox': {'Width': 0.11512646824121475,\n",
       "      'Height': 0.18408644199371338,\n",
       "      'Left': 0.7206801772117615,\n",
       "      'Top': 0.5393530130386353},\n",
       "     'Confidence': 96.36245727539062},\n",
       "    {'BoundingBox': {'Width': 0.07577159255743027,\n",
       "      'Height': 0.05097740888595581,\n",
       "      'Left': 0.38405364751815796,\n",
       "      'Top': 0.4079875648021698},\n",
       "     'Confidence': 90.39820861816406},\n",
       "    {'BoundingBox': {'Width': 0.040288351476192474,\n",
       "      'Height': 0.061054568737745285,\n",
       "      'Left': 0.5264694094657898,\n",
       "      'Top': 0.41923946142196655},\n",
       "     'Confidence': 90.10820770263672},\n",
       "    {'BoundingBox': {'Width': 0.02465815469622612,\n",
       "      'Height': 0.037095218896865845,\n",
       "      'Left': 0.33306950330734253,\n",
       "      'Top': 0.41200366616249084},\n",
       "     'Confidence': 82.01131439208984},\n",
       "    {'BoundingBox': {'Width': 0.048830606043338776,\n",
       "      'Height': 0.10315806418657303,\n",
       "      'Left': 0.2657257914543152,\n",
       "      'Top': 0.3941638469696045},\n",
       "     'Confidence': 78.51365661621094},\n",
       "    {'BoundingBox': {'Width': 0.02585400640964508,\n",
       "      'Height': 0.18228760361671448,\n",
       "      'Left': 0.00024881958961486816,\n",
       "      'Top': 0.6508803367614746},\n",
       "     'Confidence': 78.16555786132812},\n",
       "    {'BoundingBox': {'Width': 0.08038263022899628,\n",
       "      'Height': 0.0927431732416153,\n",
       "      'Left': 0.7048985958099365,\n",
       "      'Top': 0.48333680629730225},\n",
       "     'Confidence': 77.78471374511719},\n",
       "    {'BoundingBox': {'Width': 0.058656979352235794,\n",
       "      'Height': 0.0702885091304779,\n",
       "      'Left': 0.5975759625434875,\n",
       "      'Top': 0.4865652322769165},\n",
       "     'Confidence': 73.09712982177734},\n",
       "    {'BoundingBox': {'Width': 0.023524189367890358,\n",
       "      'Height': 0.03658650815486908,\n",
       "      'Left': 0.3151436746120453,\n",
       "      'Top': 0.4157564342021942},\n",
       "     'Confidence': 61.80812072753906},\n",
       "    {'BoundingBox': {'Width': 0.02781086042523384,\n",
       "      'Height': 0.0660419911146164,\n",
       "      'Left': 0.5614835619926453,\n",
       "      'Top': 0.4459336996078491},\n",
       "     'Confidence': 53.16584777832031}],\n",
       "   'Parents': [{'Name': 'Vehicle'}, {'Name': 'Transportation'}]},\n",
       "  {'Name': 'Automobile',\n",
       "   'Confidence': 99.82917022705078,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Vehicle'}, {'Name': 'Transportation'}]},\n",
       "  {'Name': 'Vehicle',\n",
       "   'Confidence': 99.82917022705078,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Transportation'}]},\n",
       "  {'Name': 'Transportation',\n",
       "   'Confidence': 99.82917022705078,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Road',\n",
       "   'Confidence': 99.17877197265625,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Light',\n",
       "   'Confidence': 96.97900390625,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Traffic Light',\n",
       "   'Confidence': 96.97900390625,\n",
       "   'Instances': [{'BoundingBox': {'Width': 0.00623741140589118,\n",
       "      'Height': 0.02140810154378414,\n",
       "      'Left': 0.5180245637893677,\n",
       "      'Top': 0.3407004773616791},\n",
       "     'Confidence': 96.97900390625},\n",
       "    {'BoundingBox': {'Width': 0.01377792377024889,\n",
       "      'Height': 0.03527013957500458,\n",
       "      'Left': 0.5049911141395569,\n",
       "      'Top': 0.28405269980430603},\n",
       "     'Confidence': 95.9166030883789},\n",
       "    {'BoundingBox': {'Width': 0.008427905850112438,\n",
       "      'Height': 0.027121776714920998,\n",
       "      'Left': 0.4626537263393402,\n",
       "      'Top': 0.3254183530807495},\n",
       "     'Confidence': 87.78636932373047}],\n",
       "   'Parents': [{'Name': 'Light'}]}],\n",
       " 'LabelModelVersion': '2.0',\n",
       " 'ResponseMetadata': {'RequestId': '3f18adf4-ac6f-11e9-b8d4-ad0bd2e26e24',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 22 Jul 2019 10:55:42 GMT',\n",
       "   'x-amzn-requestid': '3f18adf4-ac6f-11e9-b8d4-ad0bd2e26e24',\n",
       "   'content-length': '3538',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Detecting Using S3 Bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.detect_labels(Image={'S3Object':{'Bucket': 'sonuresob1','Name': photo}},\n",
    "                                MaxLabels=10,MinConfidence=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   2. Face recial Analysis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = client.detect_faces(Image={'S3Object':{'Bucket': 'sonuresob1','Name': '11.jpg'}},Attributes=['ALL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['BoundingBox', 'AgeRange', 'Smile', 'Eyeglasses', 'Sunglasses', 'Gender', 'Beard', 'Mustache', 'EyesOpen', 'MouthOpen', 'Emotions', 'Landmarks', 'Pose', 'Quality', 'Confidence'])\n",
      "---------------------------\n",
      "Age Range:  {'Low': 26, 'High': 43}\n",
      "Gender:  {'Value': 'Male', 'Confidence': 99.9787368774414}\n",
      "Smile:  {'Value': False, 'Confidence': 99.57845306396484}\n",
      "Emotions:  [{'Type': 'SAD', 'Confidence': 3.511714220046997}, {'Type': 'SURPRISED', 'Confidence': 1.2579584121704102}, {'Type': 'ANGRY', 'Confidence': 5.19409704208374}, {'Type': 'CALM', 'Confidence': 59.725093841552734}, {'Type': 'HAPPY', 'Confidence': 0.8363337516784668}, {'Type': 'DISGUSTED', 'Confidence': 1.610154151916504}, {'Type': 'CONFUSED', 'Confidence': 27.864646911621094}]\n",
      "=============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use loop in case multiple people in the image:\n",
    "for key,value in response2.items():\n",
    "    if key=='FaceDetails':\n",
    "        for people_att in value:\n",
    "            print(people_att.keys())\n",
    "            print('---------------------------')\n",
    "            print('Age Range: ',people_att['AgeRange'])\n",
    "            print('Gender: ',people_att['Gender'])\n",
    "            print('Smile: ',people_att['Smile'])\n",
    "            print('Emotions: ',people_att['Emotions'])\n",
    "            print('=============================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   3. Comparing two images for the match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "response3 = client.compare_faces(SourceImage={'S3Object': {'Bucket': 'sonuresob1','Name': '11.jpg'}}, \n",
    "                                TargetImage={'S3Object': {'Bucket': 'sonuresob1','Name': '07.jpg'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SourceImageFace': {'BoundingBox': {'Width': 0.1779618263244629,\n",
       "   'Height': 0.3592563271522522,\n",
       "   'Left': 0.5863519906997681,\n",
       "   'Top': 0.15845666825771332},\n",
       "  'Confidence': 99.99998474121094},\n",
       " 'FaceMatches': [{'Similarity': 96.88172149658203,\n",
       "   'Face': {'BoundingBox': {'Width': 0.12957529723644257,\n",
       "     'Height': 0.29724517464637756,\n",
       "     'Left': 0.4368344843387604,\n",
       "     'Top': 0.22759073972702026},\n",
       "    'Confidence': 99.99998474121094,\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.4551735520362854,\n",
       "      'Y': 0.3384191393852234},\n",
       "     {'Type': 'eyeRight', 'X': 0.5117777585983276, 'Y': 0.3355780243873596},\n",
       "     {'Type': 'mouthLeft', 'X': 0.4620724022388458, 'Y': 0.4403378665447235},\n",
       "     {'Type': 'mouthRight', 'X': 0.5084807276725769, 'Y': 0.43834608793258667},\n",
       "     {'Type': 'nose', 'X': 0.4729882776737213, 'Y': 0.387184739112854}],\n",
       "    'Pose': {'Roll': -6.285496711730957,\n",
       "     'Yaw': -24.9992733001709,\n",
       "     'Pitch': 10.211874008178711},\n",
       "    'Quality': {'Brightness': 87.61164093017578,\n",
       "     'Sharpness': 83.14741516113281}}}],\n",
       " 'UnmatchedFaces': [{'BoundingBox': {'Width': 0.14284607768058777,\n",
       "    'Height': 0.28226906061172485,\n",
       "    'Left': 0.1048223003745079,\n",
       "    'Top': 0.3850671350955963},\n",
       "   'Confidence': 100.0,\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.14016906917095184,\n",
       "     'Y': 0.48807862401008606},\n",
       "    {'Type': 'eyeRight', 'X': 0.20575980842113495, 'Y': 0.4859619736671448},\n",
       "    {'Type': 'mouthLeft', 'X': 0.14633099734783173, 'Y': 0.583676278591156},\n",
       "    {'Type': 'mouthRight', 'X': 0.2011963576078415, 'Y': 0.5818026661872864},\n",
       "    {'Type': 'nose', 'X': 0.17593620717525482, 'Y': 0.5441035032272339}],\n",
       "   'Pose': {'Roll': -3.3172767162323,\n",
       "    'Yaw': -5.155028820037842,\n",
       "    'Pitch': 6.59484338760376},\n",
       "   'Quality': {'Brightness': 82.45086669921875,\n",
       "    'Sharpness': 60.49041748046875}},\n",
       "  {'BoundingBox': {'Width': 0.1306096613407135,\n",
       "    'Height': 0.2656841576099396,\n",
       "    'Left': 0.16117842495441437,\n",
       "    'Top': 0.06208300590515137},\n",
       "   'Confidence': 99.99998474121094,\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.19314658641815186,\n",
       "     'Y': 0.16197754442691803},\n",
       "    {'Type': 'eyeRight', 'X': 0.2533811926841736, 'Y': 0.15412801504135132},\n",
       "    {'Type': 'mouthLeft', 'X': 0.20583581924438477, 'Y': 0.25870102643966675},\n",
       "    {'Type': 'mouthRight', 'X': 0.25556430220603943, 'Y': 0.25207337737083435},\n",
       "    {'Type': 'nose', 'X': 0.23192881047725677, 'Y': 0.20091590285301208}],\n",
       "   'Pose': {'Roll': -4.816690444946289,\n",
       "    'Yaw': 7.666775226593018,\n",
       "    'Pitch': 6.95406436920166},\n",
       "   'Quality': {'Brightness': 84.34928131103516,\n",
       "    'Sharpness': 83.14741516113281}},\n",
       "  {'BoundingBox': {'Width': 0.13313937187194824,\n",
       "    'Height': 0.2770807445049286,\n",
       "    'Left': 0.6495131850242615,\n",
       "    'Top': 0.20961341261863708},\n",
       "   'Confidence': 99.99998474121094,\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.6647353172302246,\n",
       "     'Y': 0.31380876898765564},\n",
       "    {'Type': 'eyeRight', 'X': 0.728597104549408, 'Y': 0.2958455979824066},\n",
       "    {'Type': 'mouthLeft', 'X': 0.6799237132072449, 'Y': 0.41318684816360474},\n",
       "    {'Type': 'mouthRight', 'X': 0.7330917119979858, 'Y': 0.3980734944343567},\n",
       "    {'Type': 'nose', 'X': 0.697039783000946, 'Y': 0.3617934584617615}],\n",
       "   'Pose': {'Roll': -9.610604286193848,\n",
       "    'Yaw': -7.6942596435546875,\n",
       "    'Pitch': 6.768851280212402},\n",
       "   'Quality': {'Brightness': 77.38951110839844,\n",
       "    'Sharpness': 83.14741516113281}},\n",
       "  {'BoundingBox': {'Width': 0.1635652482509613,\n",
       "    'Height': 0.30700013041496277,\n",
       "    'Left': 0.7917631268501282,\n",
       "    'Top': 0.28239575028419495},\n",
       "   'Confidence': 99.99998474121094,\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.8221045136451721,\n",
       "     'Y': 0.39647039771080017},\n",
       "    {'Type': 'eyeRight', 'X': 0.89528888463974, 'Y': 0.37528520822525024},\n",
       "    {'Type': 'mouthLeft', 'X': 0.8429458737373352, 'Y': 0.5065866708755493},\n",
       "    {'Type': 'mouthRight', 'X': 0.9040648341178894, 'Y': 0.489116370677948},\n",
       "    {'Type': 'nose', 'X': 0.8622167706489563, 'Y': 0.44910910725593567}],\n",
       "   'Pose': {'Roll': -10.905336380004883,\n",
       "    'Yaw': 6.827350616455078,\n",
       "    'Pitch': 2.3279266357421875},\n",
       "   'Quality': {'Brightness': 79.3301773071289,\n",
       "    'Sharpness': 92.22801208496094}}],\n",
       " 'ResponseMetadata': {'RequestId': 'a65f6538-ac63-11e9-8ee1-2511b4763c72',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Mon, 22 Jul 2019 09:32:41 GMT',\n",
       "   'x-amzn-requestid': 'a65f6538-ac63-11e9-8ee1-2511b4763c72',\n",
       "   'content-length': '3538',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
